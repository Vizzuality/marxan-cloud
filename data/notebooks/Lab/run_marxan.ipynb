{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import os\n",
    "import io\n",
    "import re\n",
    "import csv\n",
    "from shutil import rmtree\n",
    "\n",
    "from datetime import datetime\n",
    "import abc\n",
    "import collections\n",
    "from typing import Generic, TypeVar, Generic, Optional, List, Type\n",
    "from pydantic import BaseModel, ValidationError, validator, Field\n",
    "from pydantic.generics import GenericModel\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import qgrid\n",
    "from IPython.display import display, JSON\n",
    "import ipywidgets as widgets\n",
    "\n",
    "import json\n",
    "\n",
    "from uuid import UUID, uuid4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "MARXAN_FOLDER = '/home/jovyan/work/datasets/raw/marxan_Coral_Triangle_Case_Study_mod'\n",
    "MARXAN_EXECUTABLE = f'{MARXAN_FOLDER}/MarOpt_v243_Linux64'\n",
    "MARXAN_INPUTDATA = 'input.dat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DebugTraceFile_MarOpt.txt  MarOptTotalAreas.csv  output_0.001  output_1\n",
      "input\t\t\t   MarOpt_v243_Linux64\t output_0.01   output_10\n",
      "input.dat\t\t   output\t\t output_0.1    output_100\n",
      " boundary.dat\t\t\t      pu.dat\n",
      "'Coral Triangle Costs Profile.cost'   puvspr.dat\n",
      " feature_preprocessing.dat\t      spec.dat\n",
      " protected_area_intersections.dat     spec_notarget.dat\n"
     ]
    }
   ],
   "source": [
    "# Help edit the .dat files\n",
    "!ls $MARXAN_FOLDER\n",
    "!ls $MARXAN_FOLDER/input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper clases and funtions for reading and data mutation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatFile(object):\n",
    "    \"\"\"\n",
    "    Read and write dat files.\n",
    "    \"\"\"\n",
    "    def __init__(self, file_path: str = None):\n",
    "        # Ensure the file has the right extension\n",
    "        if file_path and not file_path.endswith('.dat'):\n",
    "            raise NameError(\"File must be a '.dat' extension\")\n",
    "        \n",
    "        self.__path = file_path\n",
    "        self.data = None\n",
    "        \n",
    "    def __test_path(self, path):\n",
    "        if not self.__path and path:\n",
    "            self.__path = path\n",
    "        elif not self.__path and not path:\n",
    "            raise NameError('No path to file provided')\n",
    "    \n",
    "    def update(self, data, incremental: bool = False ):\n",
    "        \"\"\"Updates the data.\n",
    "    \n",
    "        Args:\n",
    "            data (any): The data the object should store.\n",
    "        Returns:\n",
    "            The contents of the file as a unicode string.\n",
    "        \"\"\"\n",
    "        __conversion: dict = {\n",
    "                                int: int,\n",
    "                                str: str,\n",
    "                                dict: dict,\n",
    "                                list: list\n",
    "                            }\n",
    "        if not incremental or not self.data:\n",
    "            self.data = data\n",
    "        elif type(self.data) == dict:\n",
    "            self.data.append(data)\n",
    "        else:\n",
    "            self.data = self.data + __conversion[type(self.data)](data)\n",
    "        \n",
    "    \n",
    "    def read(self, file_path: str = None):\n",
    "        \"\"\"Gets a files contents as a unicode string.\n",
    "    \n",
    "        Args:\n",
    "            filename (string): The full path to the file that will be read.\n",
    "        Returns:\n",
    "            The contents of the file as a unicode string.\n",
    "        \"\"\"\n",
    "        self.__test_path(file_path)\n",
    "        try:\n",
    "            with io.open(self.__path, mode=\"r\", encoding=\"utf-8\") as f:\n",
    "                self.data = f.readlines()\n",
    "        except (UnicodeDecodeError) as e:\n",
    "            with io.open(self.__path, mode=\"r\", encoding=\"ISO-8859-1\") as f:\n",
    "                self.data = f.read()\n",
    "        except Exception as e:\n",
    "            raise e\n",
    "    \n",
    "    def write(self, file_path: str = None):\n",
    "        \"\"\"Writes a files contents as a unicode string\n",
    "    \n",
    "        Args:\n",
    "            filename (string): The full path to the file that will be written.  \n",
    "            s (string): The unicode string to write.  \n",
    "            mode (string): Optional. The file write mode. Default value is w.  \n",
    "        Returns:\n",
    "            None  \n",
    "        \"\"\"\n",
    "        self.__test_path(file_path)\n",
    "        try:\n",
    "            with io.open(self.__path, mode, encoding=\"utf-8\") as f: \n",
    "                f.write(self.data)\n",
    "        except Exception as e:\n",
    "            raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just in case we need to format the float numbers in a very specific way\n",
    "class MyNumber:\n",
    "    \"\"\"\n",
    "    Number formater wraper to allow a specific format string for a float number.\n",
    "    \"\"\"\n",
    "    def __init__(self, val):\n",
    "        self.val = val\n",
    "\n",
    "    def __format__(self,format_spec):\n",
    "        ss = ('{0:'+format_spec+'}').format(self.val)\n",
    "        if ( 'E' in ss):\n",
    "            mantissa, exp = ss.split('E')            \n",
    "            return mantissa + 'E'+ exp[0] + '00' + exp[1:]\n",
    "        return ss\n",
    "\n",
    "def num(s):\n",
    "    \"\"\"\n",
    "    Coerce Number transformation into float.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return int(s)\n",
    "    except ValueError:\n",
    "        try:\n",
    "            return float(s)\n",
    "        except ValueError:\n",
    "            return s\n",
    "\n",
    "def getSizeOfNestedList(listOfElem):\n",
    "    ''' Get number of elements in a nested list'''\n",
    "    count = 0\n",
    "    # Iterate over the list\n",
    "    for elem in listOfElem:\n",
    "        # Check if type of element is list\n",
    "        if type(elem) == list:  \n",
    "            # Again call this function to get the size of this element\n",
    "            count += getSizeOfNestedList(elem)\n",
    "        else:\n",
    "            count += 1    \n",
    "    return count\n",
    "\n",
    "def _readTabularFile(filename: str)-> dict:\n",
    "    \"\"\"\n",
    "    Gets a input.dat file and outputs a dict of parameters.\n",
    "\n",
    "    Args:\n",
    "        filename (string): The full path to the file that will be read.\n",
    "    Returns:\n",
    "        The contents of the file as a dict.\n",
    "    \"\"\"\n",
    "    inputData = DatFile(filename)\n",
    "    inputData.read()\n",
    "    outputData = []\n",
    "    \n",
    "    dialect= csv.Sniffer().sniff(inputData.data[0],[',', '\\t',' '])\n",
    "    for line in inputData.data: \n",
    "        if dialect.delimiter ==',':\n",
    "            pair= re.compile('\\s').split(line.replace('\"','').replace(' ', '_').strip('\"\"').strip('\\r').strip('\\n').replace(',', '\\t'))\n",
    "        else:\n",
    "            pair= re.compile('\\s').split(line.replace('\"','').strip('\"\"').strip('\\r').strip('\\n'))\n",
    "        outputData.append(pair)\n",
    "    return outputData\n",
    "\n",
    "\n",
    "def CreateListModelFromFile(filename: str, model: Type['Model'])-> List['Model']:\n",
    "    \"\"\"\n",
    "    Gets a input.dat file and outputs a list of selected model.\n",
    "\n",
    "    Args:\n",
    "        filename (string): The full path to the file that will be read.\n",
    "        model (Type['Model']): Data model used to read and validate the data\n",
    "    Returns:\n",
    "        The contents of the file as a Data model list.\n",
    "    \"\"\"\n",
    "    inputData = _readTabularFile(filename)\n",
    "    return [model.parse_obj(dict(zip(inputData[0], x))) for x in inputData[1:]] \n",
    "\n",
    "def CreateFileFromDF(filename: str, df: Type['Dataframe'], model: Type['Model'])-> List[list]:\n",
    "    \"\"\"\n",
    "    Gets a dataframe and outs a dat.file.\n",
    "\n",
    "    Args:\n",
    "        filename (string): The full path to the file that will be read.\n",
    "        df (Type['Dataframe']): Dataframe to save\n",
    "        model (Type['Model']): Data model used to read and validate the data\n",
    "    Returns:\n",
    "        The contents of the file as a Data model list.\n",
    "    \"\"\"\n",
    "    if model == inputDatFile:\n",
    "        data = df.transpose().to_dict('records')\n",
    "        validatedData = [inputDatFile(**x) for x in data]\n",
    "        keys = data[0].keys()\n",
    "        csv.register_dialect('dat', delimiter=' ')\n",
    "        with open(filename, 'w', encoding='utf8', newline='')  as output_file:\n",
    "            dict_writer = csv.writer(output_file, dialect='dat')\n",
    "            for row in data[0].items():\n",
    "                dict_writer.writerow(row)\n",
    "    else:\n",
    "        data = df.to_dict('records')\n",
    "        validatedData = [model(**x) for x in data]\n",
    "#         keys = validatedData[0].__dict__.keys()\n",
    "#         csv.register_dialect('dat', delimiter='\\t')\n",
    "#         with open(filename, 'w', encoding='utf8', newline='')  as output_file:\n",
    "#             dict_writer = csv.DictWriter(output_file, keys, dialect='dat')\n",
    "#             dict_writer.writeheader()\n",
    "#         dict_writer.writerows(toCSV)\n",
    "#             dict_writer.writerows(data)\n",
    "    \n",
    "        keys={k: v for k, v in data[0].items() if v is not None}.keys()\n",
    "        dataNotNone = list(({key : val for key, val in sub.items() if val!= None} for sub in data)) \n",
    "\n",
    "        csv.register_dialect('dat', delimiter=' ')\n",
    "        with open(filename, 'w', encoding='utf8', newline='')  as output_file:\n",
    "            dict_writer = csv.DictWriter(output_file, keys, dialect='dat')\n",
    "            dict_writer.writeheader()\n",
    "            dict_writer.writerows(dataNotNone)\n",
    "    \n",
    "    \n",
    "    return validatedData\n",
    "\n",
    "def save_button(filename: str, model: Type['Model'], data: Type['QgridWidget'])-> None:\n",
    "    \"\"\"\n",
    "    creates a widget button and attach a on click event.\n",
    "    \n",
    "    Args:\n",
    "        filename (string): The full path to the file that will be read.\n",
    "        data (Type['QgridWidget']): Qgrid widget\n",
    "        model (Type['Model']): Data model used to read and validate the data\n",
    "    \"\"\"\n",
    "    button = widgets.Button(description=\"Save\")\n",
    "    output = widgets.Output()\n",
    "\n",
    "    display(button, output)\n",
    "\n",
    "    def on_button_clicked(b):\n",
    "        with output:\n",
    "            CreateFileFromDF(filename, data.get_changed_df(), model)\n",
    "\n",
    "    button.on_click(on_button_clicked)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input data model types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class inputDatFile(BaseModel):\n",
    "    \"\"\"\n",
    "    This is the description of the input data clase base on marxan input file.\n",
    "    \"\"\"\n",
    "    \n",
    "    # General Parameters\n",
    "    VERSION: str = Field('0.1', title='Version', \n",
    "                         description='Type of input file')\n",
    "    BLM:  Optional[float] = Field(0., title='Boundary Length Modifier', \n",
    "                           description='Boundary Length Modifier')\n",
    "    PROP: float = Field(0., title='Starting Proportion', \n",
    "                            description='Proportion of planning units in initial reserve system')\n",
    "    RANDSEED: Optional[int] = Field(-1, title='Random Seed', \n",
    "                              description='Random seed number')\n",
    "    NUMREPS: int = Field(1, title='Repeat Runs', \n",
    "                             description='The number of repeat runs you wish to do')\n",
    "    BESTSCORE: Optional[int] = Field(0, title='Best Score Speedup', \n",
    "                               description='This variable tells Marxan not to keep track of the best score \\\n",
    "                                until it reaches a specified minimum level.')\n",
    "    \n",
    "    # Annealing Parameters\n",
    "    NUMITNS: int = Field(0, title='Number of Iterations', \n",
    "                         description='Number of iterations for annealing')\n",
    "    STARTTEMP: int = Field(1, title='Initial Temperature', \n",
    "                           description='Starting temperature for annealing')\n",
    "    COOLFAC: int = Field(0, title='Cooling Factor', \n",
    "                         description='Cooling factor for annealing')\n",
    "    NUMTEMP: int = Field(1, title='Temperature Decreases', \n",
    "                         description='Number of temperature decreases for annealing')\n",
    "    \n",
    "    # Cost Threshold\n",
    "    COSTTHRESH: Optional[float] = Field(0, title='Threshold', \n",
    "                              description='Cost threshold')\n",
    "    THRESHPEN1: Optional[float] = Field(0, title='Penalty Factor A', \n",
    "                              description='Size of cost threshold penalty')\n",
    "    THRESHPEN2: Optional[float] = Field(0, title='Penalty Factor B', \n",
    "                              description='Shape of cost threshold penalty')\n",
    "    \n",
    "    # Input Files\n",
    "    INPUTDIR: str = Field('input', title='Input Folder', \n",
    "                          description='User Defined Name of the folder containing input data files')\n",
    "    SPECNAME: str = Field('spec.dat', title='Species File Name', \n",
    "                          description='Name of Conservation Feature File')\n",
    "    PUNAME: str = Field('pu.dat', title='Planning Unit File Name', \n",
    "                        description='Name of Planning Unit File')\n",
    "    PUVSPRNAME: str = Field('puvspr2.dat', title='Planning Unit versus Species', \n",
    "                            description='Name of Planning Unit versus Conservation Feature File')\n",
    "    BOUNDNAME: str = Field('bound.dat', title='Boundary Length', \n",
    "                           description='Name of Boundary Length File')\n",
    "    BLOCKDEFNAME: Optional[str] = Field('blockdef.dat', title='Block Definitions', \n",
    "                              description='Name of Block Definition File')\n",
    "    \n",
    "    # Output Files\n",
    "    VERBOSITY: int =  Field(1, title='Screen Output', \n",
    "                            description='Amount of output displayed on the program screen')\n",
    "    MISSLEVEL: Optional[float] =  Field(1, title='Species missing proportion', \n",
    "                              description='Amount or target below which it is counted as ‘missing’')\n",
    "    OUTPUTDIR: str = Field('output', title='', \n",
    "                           description='User Defined Name of the folder in which to save output files')\n",
    "    SCENNAME: str = Field('Default_name', title='Scenario name', \n",
    "                          description='Scenario name for the saved output files')\n",
    "    SAVERUN: Optional[int] = Field(3, title='Save each run', \n",
    "                         description='Save each run? (0 = no)')\n",
    "    SAVEBEST: Optional[int] =  Field(3, title='Save the best run', \n",
    "                           description='Save the best run? (0 = no)')\n",
    "    SAVESUMMARY: Optional[int] =  Field(3, title='Save summary', \n",
    "                          description='Save summary information? (0 = no)')\n",
    "    SAVESCEN: Optional[int] =  Field(3, title='Save scenario', \n",
    "                           description='Save scenario information? (0 = no)')\n",
    "    SAVETARGMET: Optional[int] =  Field(3, title='Save targets met', \n",
    "                              description='Save targets met information? (0 = no)')\n",
    "    SAVESUMSOLN: Optional[int] =  Field(3, title='', \n",
    "                              description='Save summed solution information? (0 = no)')\n",
    "    SAVELOG: Optional[int] =  Field(1, title='Save summed solution', \n",
    "                          description='Save log files? (0 = no)')\n",
    "    SAVESNAPSTEPS: Optional[int] =  Field(0, title='Save snapshots', \n",
    "                                description='Save snapshots each n steps (0 = no)')\n",
    "    SAVESNAPCHANGES: Optional[int] =  Field(0, title='Save snapshots changes', \n",
    "                                  description='Save snapshots after every n changes (0 = no)')\n",
    "    SAVESNAPFREQUENCY: Optional[int] =  Field(0, title='Frequency of snapshots', \n",
    "                                    description='Frequency of snapshots if they are being used')\n",
    "    SAVESOLUTIONSMATRIX: Optional[int] =  Field(3, title='Frequency of snapshots', \n",
    "                                    description='Frequency of snapshots if they are being used')\n",
    "    \n",
    "    # Program control.\n",
    "    RUNMODE: int = Field(1, title='Run Options', \n",
    "                         description='User Defined The method Marxan uses to find solutions')\n",
    "    \n",
    "    ITIMPTYPE: int =  Field(1, title='Iterative Improvement', \n",
    "                            description='Iterative improvement type')\n",
    "    HEURTYPE: int =  Field(1, title='Heuristic', \n",
    "                           description='Heuristic type')\n",
    "    CLUMPTYPE: Optional[int] =  Field(0, title='Clumping Rule', \n",
    "                            description='Clumping penalty type')\n",
    "    \n",
    "    # class Config:\n",
    "    @validator('SAVERUN')\n",
    "    def SAVERUN_is_valid(cls, method: int) -> int:\n",
    "        allowed_set = {0: 'No file generated',\n",
    "                      1: 'save a file as .dat',\n",
    "                      2: 'save a file as .txt',\n",
    "                      3: 'save a file as .csv'}\n",
    "        \n",
    "        if method not in allowed_set.keys():\n",
    "            raise ValueError(f\"must be in {allowed_set}, got '{method}'\")\n",
    "        \n",
    "        return method\n",
    "    \n",
    "    @validator('SAVEBEST')\n",
    "    def SAVEBEST_is_valid(cls, method: int) -> int:\n",
    "        allowed_set = {0: 'No file generated',\n",
    "                      1: 'save a file as .dat',\n",
    "                      2: 'save a file as .txt',\n",
    "                      3: 'save a file as .csv'}\n",
    "        \n",
    "        if method not in allowed_set.keys():\n",
    "            raise ValueError(f\"must be in {allowed_set}, got '{method}'\")\n",
    "        \n",
    "        return method\n",
    "    \n",
    "    @validator('SAVESUMMARY')\n",
    "    def SAVESUMMMARY_is_valid(cls, method: int) -> int:\n",
    "        allowed_set = {0: 'No file generated',\n",
    "                      1: 'save a file as .dat',\n",
    "                      2: 'save a file as .txt',\n",
    "                      3: 'save a file as .csv'}\n",
    "        \n",
    "        if method not in allowed_set.keys():\n",
    "            raise ValueError(f\"must be in {allowed_set}, got '{method}'\")\n",
    "        \n",
    "        return method\n",
    "    \n",
    "    @validator('SAVESCEN')\n",
    "    def SAVESCEN_is_valid(cls, method: int) -> int:\n",
    "        allowed_set = {0: 'No file generated',\n",
    "                      1: 'save a file as .dat',\n",
    "                      2: 'save a file as .txt',\n",
    "                      3: 'save a file as .csv'}\n",
    "        \n",
    "        if method not in allowed_set.keys():\n",
    "            raise ValueError(f\"must be in {allowed_set}, got '{method}'\")\n",
    "        \n",
    "        return method\n",
    "    \n",
    "    @validator('SAVETARGMET')\n",
    "    def SAVETARGMET_is_valid(cls, method: int) -> int:\n",
    "        allowed_set = {0: 'No file generated',\n",
    "                      1: 'save a file as .dat',\n",
    "                      2: 'save a file as .txt',\n",
    "                      3: 'save a file as .csv'}\n",
    "        \n",
    "        if method not in allowed_set.keys():\n",
    "            raise ValueError(f\"must be in {allowed_set}, got '{method}'\")\n",
    "        \n",
    "        return method\n",
    "    \n",
    "    @validator('SAVESUMSOLN')\n",
    "    def SAVESUMSOLN_is_valid(cls, method: int) -> int:\n",
    "        allowed_set = {0: 'No file generated',\n",
    "                      1: 'save a file as .dat',\n",
    "                      2: 'save a file as .txt',\n",
    "                      3: 'save a file as .csv'}\n",
    "        \n",
    "        if method not in allowed_set.keys():\n",
    "            raise ValueError(f\"must be in {allowed_set}, got '{method}'\")\n",
    "        \n",
    "        return method\n",
    "    \n",
    "    @validator('SAVELOG')\n",
    "    def SAVELOG_is_valid(cls, method: int) -> int:\n",
    "        allowed_set = {0: 'No file generated',\n",
    "                      1: 'save a file as .dat',\n",
    "                      2: 'save a file as .txt',\n",
    "                      3: 'save a file as .csv'}\n",
    "        \n",
    "        if method not in allowed_set.keys():\n",
    "            raise ValueError(f\"must be in {allowed_set}, got '{method}'\")\n",
    "        \n",
    "        return method\n",
    "    \n",
    "    @validator('SAVESOLUTIONSMATRIX')\n",
    "    def SAVESOLUTIONSMATRIX_is_valid(cls, method: int) -> int:\n",
    "        allowed_set = {0: 'No file generated',\n",
    "                      1: 'save a file as .dat',\n",
    "                      2: 'save a file as .txt',\n",
    "                      3: 'save a file as .csv'}\n",
    "        \n",
    "        if method not in allowed_set.keys():\n",
    "            raise ValueError(f\"must be in {allowed_set}, got '{method}'\")\n",
    "        \n",
    "        return method\n",
    "    \n",
    "    @validator('RUNMODE')\n",
    "    def RUNMODE_is_valid(cls, method: int) -> int:\n",
    "        allowed_set = {0: 'Apply Simulated Annealing followed by a Heuristic',\n",
    "                      1: 'Apply Simulated Annealing followed by Iterative Improvement',\n",
    "                      2: 'Apply Simulated Annealing followed by a Heuristic, followed by Iterative',\n",
    "                      3: 'Use only a Heuristic',\n",
    "                      4: 'Use only Iterative Improvement',\n",
    "                      5: 'Use a Heuristic followed by Iterative Improvement',\n",
    "                      6: 'Use only Simulated Annealing'}\n",
    "        \n",
    "        if method not in allowed_set.keys():\n",
    "            raise ValueError(f\"must be in {allowed_set}, got '{method}'\")\n",
    "        \n",
    "        return method\n",
    "    \n",
    "    @validator('ITIMPTYPE')\n",
    "    def ITIMPTYPE_is_valid(cls, method: int) -> int:\n",
    "        allowed_set = {0: 'Normal Iterative Improvement',\n",
    "                      1: 'Two Step Iterative Improvement',\n",
    "                      2: '‘Swap’ Iterative Improvement',\n",
    "                      3: 'Normal Improvement followed by Two Step Iterative Improvement'}\n",
    "        \n",
    "        if method not in allowed_set.keys():\n",
    "            raise ValueError(f\"must be in {allowed_set}, got '{method}'\")\n",
    "        \n",
    "        return method\n",
    "    \n",
    "    @validator('HEURTYPE')\n",
    "    def HEURTYPE_is_valid(cls, method: int) -> int:\n",
    "        allowed_set = {-1:'Ignored',\n",
    "                      0: 'Richness',\n",
    "                      1: 'Greedy',\n",
    "                      2: 'Max Rarity',\n",
    "                      3: 'Best Rarity',\n",
    "                      4: 'Average Rarity',\n",
    "                      5: 'Sum Rarity',\n",
    "                      6: 'Product Irreplaceability',\n",
    "                      7: 'Summation Irreplaceability'}\n",
    "        \n",
    "        if method not in allowed_set.keys():\n",
    "            raise ValueError(f\"must be in {allowed_set}, got '{method}'\")\n",
    "        \n",
    "        return method\n",
    "    \n",
    "    @validator('VERBOSITY')\n",
    "    def VERBOSITY_is_valid(cls, method: int) -> int:\n",
    "        allowed_set = {-1:'Ignored',\n",
    "                      0: 'Silent Running',\n",
    "                      1: 'Results Only',\n",
    "                      2: 'General Progress',\n",
    "                      3: 'Detailed Progress'}\n",
    "        \n",
    "        if method not in allowed_set.keys():\n",
    "            raise ValueError(f\"must be in {allowed_set}, got '{method}'\")\n",
    "        \n",
    "        return method\n",
    "    \n",
    "    @validator('CLUMPTYPE')\n",
    "    def CLUMPTYPE_is_valid(cls, method: int) -> int:\n",
    "        allowed_set = {-1:'Ignored',\n",
    "                       0: 'Partial clumps do not count',\n",
    "                       1: 'Partial clumps count half',\n",
    "                       3: 'Graduated penalty'}\n",
    "        \n",
    "        if method not in allowed_set.keys():\n",
    "            raise ValueError(f\"must be in {allowed_set}, got '{method}'\")\n",
    "        \n",
    "        return method\n",
    "    \n",
    "    def to_dat(self):\n",
    "        \"\"\"\n",
    "        Gets a input.dat file and outputs a dict of parameters.\n",
    "\n",
    "        Args:\n",
    "            \n",
    "        Returns:\n",
    "            The data model converted on a readeable dat string.\n",
    "        \"\"\"\n",
    "        s:str = ''\n",
    "        for key, value in self.dict().items():\n",
    "            #add the key\n",
    "            s = s + key + \" \" + str(value) + \"\\n\"\n",
    "        return s\n",
    "    \n",
    "    @classmethod\n",
    "    def from_dat(cls: Type['Model'], dat: str)-> 'Model':\n",
    "        \"\"\"\n",
    "        Gets a input.dat file and outputs a dict of parameters.\n",
    "\n",
    "        Args:\n",
    "            filename (string): The full path to the file that will be read.\n",
    "        Returns:\n",
    "            The contents of the file as a dict.\n",
    "        \"\"\"\n",
    "        obj = {}\n",
    "        \n",
    "        for line in dat:\n",
    "            if re.search('[A-Z1-9_]{2,}', line, re.DOTALL):\n",
    "                pair = line.strip('\\r').strip('\\n').split(' ')\n",
    "                pair =list(filter(None, pair)) ## delete empty lists\n",
    "                if len(pair)>2: #remove lists that have more values\n",
    "                    continue\n",
    "                assert len(pair) == 2 # if the list has more or less attribute than 2 it means we have make a mistake spliting stuff\n",
    "                obj[pair[0]] = num(pair[1].strip(' '))\n",
    "                \n",
    "        return cls.parse_obj(obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class conservationFeature(BaseModel):\n",
    "    \"\"\"\n",
    "    The Conservation Feature File contains information about each of the conservation\n",
    "    features being considered, such as their name, target representation, and the penalty\n",
    "    if the representation target is not met. It has the default name ‘spec.dat’. Because of\n",
    "    this name it is sometimes referred to as the Species File, although conservation\n",
    "    features will oftenbe surrogates such as habitat type rather than actual species. \n",
    "    \"\"\"\n",
    "   \n",
    "    id: int = Field(..., title='Conservation Feature ID', \n",
    "                    description='A unique numerical identifier for each conservation feature. \\\n",
    "                                Be careful not to duplicate id numbers as Marxan will ignore all but the last one.')\n",
    "    \n",
    "    # All variables you wish to take on Block Definition attributes should\n",
    "    # have their value entered as -1 in the Conservation Feature File\n",
    "    type: Optional[int] = Field(title='Conservation Feature Type', \n",
    "                                description='Used to define groups of conservation features for which a number of \\\n",
    "                                umbrella attributes can be set for all features within the specified group (or “type”). \\\n",
    "                                Each group of features must have a unique numerical identifier. This variable is used \\\n",
    "                                in conjunction with the Block Definition File (see Section 3.3.2) which will contain \\\n",
    "                                the attributes to be assigned to a particular group of conservation features.')\n",
    "    \n",
    "    # If Block Definition File is being used for this feature, then the Target for Feature \n",
    "    # Occurrences should be set to -1 here.\n",
    "    target: Optional[float] = Field(title=' Feature Representation Target', \n",
    "                          description='The target amount of each conservation feature to be included \\\n",
    "                                        in the solutions. These values represent constraints on potential solutions \\\n",
    "                                        to the reserve selection problem. That is, for a reserve solution to be \\\n",
    "                                        feasible it must include at least this amount of each feature. The target \\\n",
    "                                        value is expressed in the same units used to define the amount of each feature in \\\n",
    "                                        each planning unit, contained in the Planning Unit versus Conservation Feature \\\n",
    "                                        File (see Section 3.2.4). However, units from different conservation features can vary \\\n",
    "                                        (e.g. hectares of habitat for one feature and number of occurrences for another, nests \\\n",
    "                                        for a third and length of stream for a fourth).')\n",
    "    \n",
    "    # If Block Definition File is being used for this feature, then the Target for Feature \n",
    "    # Occurrences should be set to -1 here.\n",
    "    prop: Optional[float] = Field(title='Proportion Target for Feature Representation', \n",
    "                                description='The variable ‘prop’, is short for proportion and can \\\n",
    "                                            be used to set the proportion (i.e. percentage) of a \\\n",
    "                                            conservation feature to be included in the reserve system.',\n",
    "                               ge =0, le =1)\n",
    "    \n",
    "    # If Block Definition File is being used for this feature, then the Target for Feature \n",
    "    # Occurrences should be set to -1 here.\n",
    "    \n",
    "    spf: float = Field(..., title='Conservation Feature Penalty Factor', \n",
    "                       description='The letters ‘spf’ stands for Species Penalty Factor. This \\\n",
    "                                    variable is more correctly referred to as the Conservation Feature Penalty \\\n",
    "                                    Factor.')\n",
    "    target2: Optional[float] = Field(title='Minimum Clump Size', \n",
    "                                     description='This variable specifies a minimum clump size for the\\\n",
    "                                                representation of conservation features in the reserve system. If the amount\\\n",
    "                                                of a conservation feature found in a clump is less that this value, then it does\\\n",
    "                                                not count towards meeting the conservation target')\n",
    "    \n",
    "    # If Block Definition File is being used for this feature, then the Target for Feature \n",
    "    # Occurrences should be set to -1 here.\n",
    "    targetocc: Optional[float] = Field(title='Target for Feature Occurrences', \n",
    "                                       description='This variable specifies the minimum number of occurrences of a\\\n",
    "                                                    conservation feature required in a reserve system. This value can be used in\\\n",
    "                                                    situations where even though your conservation target may be met in one planning\\\n",
    "                                                    unit, you would like it to be represented in a greater number of planning units,\\\n",
    "                                                    possibly for risk spreading')\n",
    "    \n",
    "    name: Optional[str] = Field(title='Conservation Feature Name', \n",
    "                                description='The alphabetical (no numbers!) name of each conservation feature')\n",
    "    \n",
    "    # If Block Definition File is being used for this feature, then the Target for Feature \n",
    "    # Occurrences should be set to -1 here.\n",
    "    sepnum: Optional[float] = Field(title='Target for Separated Feature Occurrences', \n",
    "                                    description='The number of mutually separated occurrences of a feature \\\n",
    "                                                required in the reserve system')\n",
    "    \n",
    "    # If Block Definition File is being used for this feature, then the Target for Feature \n",
    "    # Occurrences should be set to -1 here.\n",
    "    sepdistance: Optional[float] = Field(title='Minimum Separation Distance', \n",
    "                                      description=' Used in conjunction with ‘sepnum’ (above), this variable specifies\\\n",
    "                                                    the minimum distance at which planning units holding a conservation feature\\\n",
    "                                                    are considered to be separate.')\n",
    "\n",
    "     \n",
    "    #Add validator to check either target or prop are present\n",
    "    #But doesn't trigger\n",
    "    @validator('prop')\n",
    "    def check_prop_or_target(cls, v, values):\n",
    "        if 'target' not in values and not prop:\n",
    "            raise ValueError('either field target or prop is required')\n",
    "        return prop\n",
    "    \n",
    "                 \n",
    "class planningUnits(BaseModel):\n",
    "    \"\"\"\n",
    "    The Planning Unit File contains all the information related to planning units, except\n",
    "    for the distribution of conservation features across planning units (which is held in the\n",
    "    Planning Unit versus Conservation Feature File ). The default name for this file is\n",
    "    ‘pu.dat’.\n",
    "    \"\"\"\n",
    "    id: int = Field(..., title=' Planning Unit ID', \n",
    "                    description='A unique numerical identifier for each planning unit')\n",
    "    cost: Optional[float] = Field(1, title='Planning Unit Cost', \n",
    "                        description='The cost of including each planning unit in the reserve system. ')\n",
    "    status: Optional[int] = Field(0, title='Planning Unit Status', \n",
    "                          description='This variable defines whether a planning unit (PU) is locked in or out of\\\n",
    "                                      the initial and final reserve systems. It can take one of four values:')\n",
    "    \n",
    "    # This variable is only required if a minimum separation between feature occurrences has been specified in the\n",
    "    # ‘sepdistance’ column of the Conservation Feature File \n",
    "    xloc: Optional[float] = Field(title='X Planning Unit Location', \n",
    "                          description='The x-axis coordinate of the planning unit')\n",
    "    \n",
    "    # This variable is only required if a minimum separation between feature occurrences has been specified in the\n",
    "    # ‘sepdistance’ column of the Conservation Feature File \n",
    "    yloc: Optional[float] = Field(title='Y Planning Unit Location', \n",
    "                          description='The y-axis coordinate of the planning unit')\n",
    "    \n",
    "    @validator('status')\n",
    "    def status_is_valid(cls, method: int) -> int:\n",
    "        allowed_set = {\n",
    "                       0: 'The PU is not guaranteed to be in the initial reserve',\n",
    "                       1: 'The PU will be included in the initial reserve',\n",
    "                       2: 'The PU is fixed in the reserve system (“locked in”).\\\n",
    "                           It starts in the initial reserve system and cannot be removed.',\n",
    "                       3: 'The PU is fixed outside the reserve system (“locked out”).\\\n",
    "                       It is not included in the initial reserve system and cannot be added.'\n",
    "                      }\n",
    "        \n",
    "        if method not in allowed_set.keys():\n",
    "            raise ValueError(f\"must be in {allowed_set}, got '{method}'\")\n",
    "        \n",
    "        return method\n",
    "\n",
    "\n",
    "class planningUnitVSConservationFeatureV(BaseModel):\n",
    "    \"\"\"\n",
    "    The Planning Unit versus Conservation Feature File contains information on the\n",
    "    distribution of conservation features across planning units. It has the default file\n",
    "    name, ‘puvpsr2.dat’. There are two different formats this file can take, vertical and\n",
    "    horizontal. Either is acceptable and Marxan will test the header line to determine\n",
    "    which format is being used. This one represent the vertical format\n",
    "    \"\"\"\n",
    "    species: int = Field(..., title='Conservation Feature ID', \n",
    "                         description='The unique id number of each conservation feature. This must \\\n",
    "                                    correspond to the id numbers used in the Conservation Feature File.')\n",
    "    pu: int = Field(..., title='Planning Unit ID', \n",
    "                         description='The id of a planning unit where the conservation feature listed on \\\n",
    "                                    the same row occurs. The planning unit id numbers must correspond \\\n",
    "                                    to the numbers used in the Planning Unit File')\n",
    "    amount: float = Field(..., title='Conservation Feature Amount', \n",
    "                         description='The amount of the conservation feature occurring in the planning unit \\\n",
    "                                      listed on the same row. This amount may be related to the abundance \\\n",
    "                                      of a species or the extent of a certain habitat type. ',\n",
    "                          gt=0)\n",
    "\n",
    "class planningUnitVSConservationFeatureH(BaseModel):\n",
    "    \"\"\"\n",
    "    The Planning Unit versus Conservation Feature File contains information on the\n",
    "    distribution of conservation features across planning units. It has the default file\n",
    "    name, ‘puvpsr2.dat’. There are two different formats this file can take, vertical and\n",
    "    horizontal. Either is acceptable and Marxan will test the header line to determine\n",
    "    which format is being used. . This one represent the horizontal format:\n",
    "    the Planning Unit versus Conservation Feature File is simply a matrix of \n",
    "    planning units versus conservation features.\n",
    "    \"\"\"\n",
    "    pu: int = Field(..., title='Planning Unit ID',\n",
    "                    description='Amount of output displayed on the program screen')\n",
    "    species: List[int] = Field(..., title='Conservation Feature IDs', \n",
    "                               description='The unique id number of each conservation feature.')\n",
    "    amount: List[float] = Field(..., title='Conservation Feature Amount', \n",
    "                                 description='The amount of the conservation feature occurring in the planning unit \\\n",
    "                                             listed on the same row',\n",
    "                                 gt=0)\n",
    "\n",
    "\n",
    "### Optional data file structures\n",
    "\n",
    "class boundaryLength(BaseModel):\n",
    "    \"\"\"\n",
    "    The Boundary Length File contains information about the length or ‘effective length’\n",
    "    of shared boundaries between planning units. This file is necessary if you wish to use\n",
    "    the Boundary Length Modifier to improve the compactness of reserve solutions (bound.dat).\n",
    "    \n",
    "    !Any missing values within the file will prevent Marxan from running, for instance \n",
    "    !if ‘id1’ and ‘id2’ are set but no value for ‘boundary’ is entered.\n",
    "    \"\"\"\n",
    "    # important not to duplicate boundaries\n",
    "    id1: int = Field(..., title='Planning Unit ID', \n",
    "                     description='‘id1’ and ‘id2’ contain the id number of the two \\\n",
    "                     planning units that share a boundary.')\n",
    "    id2: int = Field(..., title=' Planning Unit ID', \n",
    "                     description='id1’ and ‘id2’ contain the id number of the two \\\n",
    "                     planning units that share a boundary.')\n",
    "    boundary: float = Field(..., title='Boundary Length', \n",
    "                           description='Boundary Length or boundary cost is relative \\\n",
    "                           measure of how important it is to include one planning unit \\\n",
    "                           in the reserve system, given the inclusion of the other.')\n",
    "        \n",
    "class blockDefinition(BaseModel):\n",
    "    \"\"\"\n",
    "    The Block Definition File is very similar to the Conservation Feature File (see\n",
    "    Section 3.2.2) and is used to set default variable values for groups of conservation\n",
    "    features. It is always used in conjunction with the Conservation Feature File.\n",
    "    \"\"\"\n",
    "    type: int = Field(..., title='Conservation Feature Type', \n",
    "                      description='A unique numerical identifier for groups of conservation features. \\\n",
    "                                   Each ‘type’ must correspond exactly with the types identified \\\n",
    "                                   in the Conservation Feature File ')\n",
    "    \n",
    "    # If this is set Planning Unit versus Conservation Feature File ‘target’, should be set to ‘-1’.\n",
    "    prop: Optional[float] = Field(default=..., title='Proportion Target for Feature Representation', \n",
    "                                description='The variable ‘prop’, is short for proportion and can \\\n",
    "                                            be used to set the proportion (i.e. percentage) of a \\\n",
    "                                            conservation feature to be included in the reserve system.',\n",
    "                               ge =0, le =1)\n",
    "        \n",
    "    target: float = Field(..., title=' Feature Representation Target', \n",
    "                          description='The target amount of each conservation feature to be included \\\n",
    "                                        in the solutions. These values represent constraints on potential solutions \\\n",
    "                                        to the reserve selection problem. That is, for a reserve solution to be \\\n",
    "                                        feasible it must include at least this amount of each feature. The target \\\n",
    "                                        value is expressed in the same units used to define the amount of each feature in \\\n",
    "                                        each planning unit, contained in the Planning Unit versus Conservation Feature \\\n",
    "                                        File (see Section 3.2.4). However, units from different conservation features can vary \\\n",
    "                                        (e.g. hectares of habitat for one feature and number of occurrences for another, nests \\\n",
    "                                        for a third and length of stream for a fourth).')   \n",
    "    spf: float = Field(-1, title='Conservation Feature Penalty Factor', \n",
    "                       description='The letters ‘spf’ stands for Species Penalty Factor. This \\\n",
    "                                    variable is more correctly referred to as the Conservation Feature Penalty \\\n",
    "                                    Factor.')\n",
    "    target2: Optional[float] = Field(-1, title='Minimum Clump Size', \n",
    "                                     description='This variable specifies a minimum clump size for the \\\n",
    "                                                representation of conservation features in the reserve system. If the amount\\\n",
    "                                                of a conservation feature found in a clump is less that this value, then it does\\\n",
    "                                                not count towards meeting the conservation target')\n",
    "    \n",
    "    targetocc: Optional[float] = Field(-1, title='Target for Feature Occurrences', \n",
    "                                       description='This variable specifies the minimum number of occurrences of a\\\n",
    "                                                    conservation feature required in a reserve system. This value can be used in\\\n",
    "                                                    situations where even though your conservation target may be met in one planning\\\n",
    "                                                    unit, you would like it to be represented in a greater number of planning units,\\\n",
    "                                                    possibly for risk spreading')\n",
    "\n",
    "    sepnum: Optional[float] = Field(-1, title='Target for Separated Feature Occurrences', \n",
    "                                  description='The number of mutually separated occurrences of a feature \\\n",
    "                                                required in the reserve system')\n",
    "    \n",
    "    sepdistance: Optional[float] = Field(-1, title='Minimum Separation Distance', \n",
    "                                      description=' Used in conjunction with ‘sepnum’ (above), this variable specifies\\\n",
    "                                                    the minimum distance at which planning units holding a conservation feature\\\n",
    "                                                    are considered to be separate.')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/IPython/core/display.py:904: UserWarning: JSON expects JSONable dict or list, not JSON strings\n",
      "  warnings.warn(\"JSON expects JSONable dict or list, not JSON strings\")\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "description": "The Conservation Feature File contains information about each of the conservation\nfeatures being considered, such as their name, target representation, and the penalty\nif the representation target is not met. It has the default name ‘spec.dat’. Because of\nthis name it is sometimes referred to as the Species File, although conservation\nfeatures will oftenbe surrogates such as habitat type rather than actual species. ",
       "properties": {
        "id": {
         "description": "A unique numerical identifier for each conservation feature.                                 Be careful not to duplicate id numbers as Marxan will ignore all but the last one.",
         "title": "Conservation Feature ID",
         "type": "integer"
        },
        "name": {
         "description": "The alphabetical (no numbers!) name of each conservation feature",
         "title": "Conservation Feature Name",
         "type": "string"
        },
        "prop": {
         "description": "The variable ‘prop’, is short for proportion and can                                             be used to set the proportion (i.e. percentage) of a                                             conservation feature to be included in the reserve system.",
         "maximum": 1,
         "minimum": 0,
         "title": "Proportion Target for Feature Representation",
         "type": "number"
        },
        "sepdistance": {
         "description": " Used in conjunction with ‘sepnum’ (above), this variable specifies                                                    the minimum distance at which planning units holding a conservation feature                                                    are considered to be separate.",
         "title": "Minimum Separation Distance",
         "type": "number"
        },
        "sepnum": {
         "description": "The number of mutually separated occurrences of a feature                                                 required in the reserve system",
         "title": "Target for Separated Feature Occurrences",
         "type": "number"
        },
        "spf": {
         "description": "The letters ‘spf’ stands for Species Penalty Factor. This                                     variable is more correctly referred to as the Conservation Feature Penalty                                     Factor.",
         "title": "Conservation Feature Penalty Factor",
         "type": "number"
        },
        "target": {
         "description": "The target amount of each conservation feature to be included                                         in the solutions. These values represent constraints on potential solutions                                         to the reserve selection problem. That is, for a reserve solution to be                                         feasible it must include at least this amount of each feature. The target                                         value is expressed in the same units used to define the amount of each feature in                                         each planning unit, contained in the Planning Unit versus Conservation Feature                                         File (see Section 3.2.4). However, units from different conservation features can vary                                         (e.g. hectares of habitat for one feature and number of occurrences for another, nests                                         for a third and length of stream for a fourth).",
         "title": " Feature Representation Target",
         "type": "number"
        },
        "target2": {
         "description": "This variable specifies a minimum clump size for the                                                representation of conservation features in the reserve system. If the amount                                                of a conservation feature found in a clump is less that this value, then it does                                                not count towards meeting the conservation target",
         "title": "Minimum Clump Size",
         "type": "number"
        },
        "targetocc": {
         "description": "This variable specifies the minimum number of occurrences of a                                                    conservation feature required in a reserve system. This value can be used in                                                    situations where even though your conservation target may be met in one planning                                                    unit, you would like it to be represented in a greater number of planning units,                                                    possibly for risk spreading",
         "title": "Target for Feature Occurrences",
         "type": "number"
        },
        "type": {
         "description": "Used to define groups of conservation features for which a number of                                 umbrella attributes can be set for all features within the specified group (or “type”).                                 Each group of features must have a unique numerical identifier. This variable is used                                 in conjunction with the Block Definition File (see Section 3.3.2) which will contain                                 the attributes to be assigned to a particular group of conservation features.",
         "title": "Conservation Feature Type",
         "type": "integer"
        }
       },
       "required": [
        "id",
        "spf"
       ],
       "title": "conservationFeature",
       "type": "object"
      },
      "text/plain": [
       "<IPython.core.display.JSON object>"
      ]
     },
     "execution_count": 47,
     "metadata": {
      "application/json": {
       "expanded": false,
       "root": "root"
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "JSON(conservationFeature.schema_json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_schema = conservationFeature.schema_json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Output datamodels types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples Read and write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new input.dat file with by default values\n",
    "test = DatFile()\n",
    "example = inputDatFile(BLM=0.1, NUMREPS =100, PUVSPRNAME= 'puvsp.dat')\n",
    "test.update(example.to_dat())\n",
    "print(test.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MARXAN_FOLDER = '/home/jovyan/work/datasets/raw/marxan_Coral_Triangle_Case_Study_mod'\n",
    "MARXAN_EXECUTABLE = f'{MARXAN_FOLDER}/MarOpt_v243_Linux64'\n",
    "MARXAN_INPUTDATA = 'input.dat'\n",
    "\n",
    "InputFile = DatFile(f'{MARXAN_FOLDER}/{MARXAN_INPUTDATA}')\n",
    "InputFile.read()\n",
    "# InputFile.write(f'{MARXAN_FOLDER}/{MARXAN_INPUTDATA}')\n",
    "\n",
    "userInputFile = inputDatFile.from_dat(InputFile.data)\n",
    "print(userInputFile.PUNAME)\n",
    "print(userInputFile.BOUNDNAME)\n",
    "print(userInputFile.SPECNAME)\n",
    "print(userInputFile.PUVSPRNAME)\n",
    "print(userInputFile.BLOCKDEFNAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example marxan project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "MARXAN_FOLDER = '/home/jovyan/work/datasets/raw/marxan_Coral_Triangle_Case_Study_mod'\n",
    "MARXAN_EXECUTABLE = f'{MARXAN_FOLDER}/MarOpt_v243_Linux64'\n",
    "MARXAN_INPUTDATA = 'input.dat'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[inputDatFile(VERSION='0.1', BLM=0.01, PROP=0.5, RANDSEED=-1, NUMREPS=10, BESTSCORE=10, NUMITNS=1000000, STARTTEMP=-1, COOLFAC=6, NUMTEMP=10000, COSTTHRESH=0.0, THRESHPEN1=14.0, THRESHPEN2=1.0, INPUTDIR='input', SPECNAME='spec_notarget.dat', PUNAME='pu.dat', PUVSPRNAME='puvspr.dat', BOUNDNAME='boundary.dat', BLOCKDEFNAME='blockdef.dat', VERBOSITY=3, MISSLEVEL=1.0, OUTPUTDIR='output_100', SCENNAME='output', SAVERUN=2, SAVEBEST=2, SAVESUM=0, SAVESCEN=2, SAVETARGMET=2, SAVESUMSOLN=2, SAVELOG=2, SAVESNAPSTEPS=0, SAVESNAPCHANGES=0, SAVESNAPFREQUENCY=0, SAVESOLUTIONSMATRIX=3, RUNMODE=1, ITIMPTYPE=0, HEURTYPE=-1, CLUMPTYPE=0)]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read an existing input.dat file\n",
    "InputFile = DatFile(f'{MARXAN_FOLDER}/{MARXAN_INPUTDATA}')\n",
    "InputFile.read()\n",
    "userInputFile = inputDatFile.from_dat(InputFile.data)\n",
    "userInputFile\n",
    "\n",
    "#Static table\n",
    "# userInputFile_df = pd.DataFrame.from_dict(userInputFile.__dict__, orient='index')\n",
    "# userInputFile_df.loc['BLM'] = 0.01\n",
    "# userInputFile_df\n",
    "# CreateFileFromDF(f'{MARXAN_FOLDER}/{MARXAN_INPUTDATA}',userInputFile_df,inputDatFile)\n",
    "\n",
    "\n",
    "# Interactive table ###\n",
    "userInputFile_df = qgrid.show_grid(pd.DataFrame.from_dict(userInputFile.__dict__, orient='index'), show_toolbar=True)\n",
    "display(userInputFile_df)\n",
    "userInputFile.dict()\n",
    "save_button(f'{MARXAN_FOLDER}/{MARXAN_INPUTDATA}', inputDatFile, userInputFile_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[inputDatFile(VERSION='0.1', BLM=0.02, PROP=0.5, RANDSEED=-1, NUMREPS=10, BESTSCORE=10, NUMITNS=1000000, STARTTEMP=-1, COOLFAC=6, NUMTEMP=10000, COSTTHRESH=0.0, THRESHPEN1=14.0, THRESHPEN2=1.0, INPUTDIR='input', SPECNAME='spec_notarget.dat', PUNAME='pu.dat', PUVSPRNAME='puvspr.dat', BOUNDNAME='boundary.dat', BLOCKDEFNAME='blockdef.dat', VERBOSITY=3, MISSLEVEL=1.0, OUTPUTDIR='output_100', SCENNAME='output', SAVERUN=2, SAVEBEST=2, SAVESUM=0, SAVESCEN=2, SAVETARGMET=2, SAVESUMSOLN=2, SAVELOG=2, SAVESNAPSTEPS=0, SAVESNAPCHANGES=0, SAVESNAPFREQUENCY=0, SAVESOLUTIONSMATRIX=3, RUNMODE=1, ITIMPTYPE=0, HEURTYPE=-1, CLUMPTYPE=0)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### MODIFICATION TO CHANGE PARAMETERSS\n",
    "# read an existing input.dat file\n",
    "InputFile = DatFile(f'{MARXAN_FOLDER}/{MARXAN_INPUTDATA}')\n",
    "InputFile.read()\n",
    "userInputFile = inputDatFile.from_dat(InputFile.data)\n",
    "\n",
    "## Modify for BLM calculations and save as new input.dat\n",
    "userInputFile.BLM = 0.02\n",
    "userInputFile.NUMREPS =10\n",
    "userInputFile.SPECNAME = 'spec_notarget.dat'\n",
    "\n",
    "userInputFile_df = pd.DataFrame.from_dict(userInputFile.__dict__, orient='index')\n",
    "CreateFileFromDF(f'{MARXAN_FOLDER}/{MARXAN_INPUTDATA}',userInputFile_df,inputDatFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Planning units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f'{MARXAN_FOLDER}/{userInputFile.INPUTDIR}/{userInputFile.PUNAME}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "704f24cb50554705a6762a8df7c14e2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "QgridWidget(grid_options={'fullWidthRows': True, 'syncColumnCellResize': True, 'forceFitColumns': True, 'defau…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e831b5185e34e9fb6c0bb4be557be1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Save', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02ee1b66f1034fe9b26de10df5729017",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "userPlanningUnits = CreateListModelFromFile(f'{MARXAN_FOLDER}/{userInputFile.INPUTDIR}/{userInputFile.PUNAME}', planningUnits)\n",
    "userPlanningUnits[:3]\n",
    "\n",
    "\n",
    "# #Static table\n",
    "# userPlanningUnits_df = pd.DataFrame([s.__dict__ for s in userPlanningUnits])\n",
    "# userPlanningUnits_df[0:3]\n",
    "# CreateFileFromDF(f'{MARXAN_FOLDER}/{userInputFile.INPUTDIR}/{userInputFile.PUNAME}',userPlaningUnits_df,planningUnits)\n",
    "\n",
    "#Interactive table\n",
    "userPlanningUnits_df = qgrid.show_grid(pd.DataFrame([s.__dict__ for s in userPlanningUnits]), show_toolbar=True)\n",
    "display(userPlanningUnits_df)\n",
    "save_button(f'{MARXAN_FOLDER}/{userInputFile.INPUTDIR}/{userInputFile.PUNAME}', planningUnits, userPlanningUnits_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conservation features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32049d34a54c47b388a9b6d2ac829910",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "QgridWidget(grid_options={'fullWidthRows': True, 'syncColumnCellResize': True, 'forceFitColumns': True, 'defau…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a21261467bed4344b7d3dc572e5ec0e2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Save', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "052419ec1b0b40b485149ce38c1d1d50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "userSpecData = CreateListModelFromFile(f'{MARXAN_FOLDER}/{userInputFile.INPUTDIR}/{userInputFile.SPECNAME}', conservationFeature)\n",
    "\n",
    "#Static \n",
    "# userSpecData_df = pd.DataFrame([s.__dict__ for s in userSpecData])\n",
    "# userSpecData_df[0:3]\n",
    "# CreateFileFromDF(f'{MARXAN_FOLDER}/{userInputFile.INPUTDIR}/{userInputFile.SPECNAME}',userSpecData_df,conservationFeature)\n",
    "\n",
    "#Intercative \n",
    "userSpecData_df = qgrid.show_grid(pd.DataFrame([s.__dict__ for s in userSpecData]), show_toolbar=True)\n",
    "display(userSpecData_df)\n",
    "save_button(f'{MARXAN_FOLDER}/{userInputFile.INPUTDIR}/{userInputFile.SPECNAME}', conservationFeature, userSpecData_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Planning units VS conservation features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the vertical file; for the horizontal one this needs to change a bit\n",
    "userPuvsp2Data = CreateListModelFromFile(f'{MARXAN_FOLDER}/{userInputFile.INPUTDIR}/{userInputFile.PUVSPRNAME}', planningUnitVSConservationFeatureV)\n",
    "\n",
    "#Static\n",
    "# userPuvsp2Data_df = pd.DataFrame([s.__dict__ for s in userPuvsp2Data])\n",
    "# userPuvsp2Data_df[0:3]\n",
    "\n",
    "#Intercative\n",
    "userPuvsp2Data_df = qgrid.show_grid(pd.DataFrame([s.__dict__ for s in userPuvsp2Data]), show_toolbar=True)\n",
    "display(userPuvsp2Data_df)\n",
    "save_button(f'{MARXAN_FOLDER}/{userInputFile.INPUTDIR}/{userInputFile.PUVSPRNAME}', planningUnitVSConservationFeatureV, userPuvsp2Data_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boundary Length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "userBoundData = CreateListModelFromFile(f'{MARXAN_FOLDER}/{userInputFile.INPUTDIR}/{userInputFile.BOUNDNAME}', boundaryLength)\n",
    "\n",
    "#Static\n",
    "# userBoundData_df = pd.DataFrame([s.__dict__ for s in userBoundData])\n",
    "# userBoundData_df[0:3]\n",
    "\n",
    "#Interactive\n",
    "userBoundData_df = qgrid.show_grid(pd.DataFrame([s.__dict__ for s in userBoundData]), show_toolbar=True)\n",
    "display(userBoundData_df)\n",
    "save_button(f'{MARXAN_FOLDER}/{userInputFile.INPUTDIR}/{userInputFile.BOUNDNAME}', boundaryLength, userBoundData_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute Marxan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MARXAN_FOLDER = '/home/jovyan/work/datasets/raw/marxan_Coral_Triangle_Case_Study'\n",
    "MARXAN_EXECUTABLE = f'{MARXAN_FOLDER}/MarOpt_v243_Linux64'\n",
    "MARXAN_INPUTDATA = 'input.dat'\n",
    "InputFile = DatFile(f'{MARXAN_FOLDER}/{MARXAN_INPUTDATA}')\n",
    "InputFile.read()\n",
    "userInputFile = inputDatFile.from_dat(InputFile.data)\n",
    "# userInputFile.BLM = blm\n",
    "# userInputFile.OUTPUTDIR =f'output_{blm}'\n",
    "# userInputFile.NUMREPS =10\n",
    "# userInputFile_df = pd.DataFrame.from_dict(userInputFile.__dict__, orient='index')\n",
    "# CreateFileFromDF(f'{MARXAN_FOLDER}/{MARXAN_INPUTDATA}',userInputFile_df,inputDatFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir(f'{MARXAN_FOLDER}/{userInputFile.OUTPUTDIR}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MARXAN_FOLDER = '/home/jovyan/work/datasets/raw/marxan_Coral_Triangle_Case_Study_mod'\n",
    "MARXAN_EXECUTABLE = f'{MARXAN_FOLDER}/MarOpt_v243_Linux64'\n",
    "MARXAN_INPUTDATA = 'input.dat'\n",
    "\n",
    "\n",
    "for blm in [0.001,0.01,0.1,1,10,100]:\n",
    "    InputFile = DatFile(f'{MARXAN_FOLDER}/{MARXAN_INPUTDATA}')\n",
    "    InputFile.read()\n",
    "    userInputFile = inputDatFile.from_dat(InputFile.data)\n",
    "    \n",
    "    ## Modify for BLM calculations and save as new input.dat\n",
    "    userInputFile.BLM = blm\n",
    "    userInputFile.OUTPUTDIR =f'output_{blm}'\n",
    "    userInputFile.NUMREPS =10\n",
    "    \n",
    "    userInputFile_df = pd.DataFrame.from_dict(userInputFile.__dict__, orient='index')\n",
    "    userInputFile_df = pd.DataFrame.from_dict(userInputFile.__dict__, orient='index')\n",
    "    userInputFile_df= userInputFile_df.drop('BLOCKDEFNAME')\n",
    "\n",
    "    CreateFileFromDF(f'{MARXAN_FOLDER}/{MARXAN_INPUTDATA}',userInputFile_df,inputDatFile)\n",
    "    \n",
    "    #os.mkdir(f'{MARXAN_FOLDER}/{userInputFile.OUTPUTDIR}')\n",
    "    #EXECUTES MARXAN\n",
    "    # Needs to execute marxan from the marxan root folder in order to make the file find the required data.\n",
    "    os.chdir(MARXAN_FOLDER)\n",
    "    with subprocess.Popen([MARXAN_EXECUTABLE],\n",
    "                             stdout=subprocess.PIPE,\n",
    "                             stderr=subprocess.STDOUT,\n",
    "                             universal_newlines=True,\n",
    "                          bufsize=-1) as process:\n",
    "        while process.poll() is None:\n",
    "            output = process.stdout.readline()\n",
    "            if output:\n",
    "                print(output.strip())\n",
    "\n",
    "    os.chdir('/home/jovyan/work/notebooks/Lab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f'{MARXAN_FOLDER}/{userInputFile.OUTPUTDIR}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "rmtree(f'{MARXAN_FOLDER}/{userInputFile.OUTPUTDIR}')\n",
    "os.mkdir(f'{MARXAN_FOLDER}/{userInputFile.OUTPUTDIR}')\n",
    "\n",
    "#EXECUTES MARXAN\n",
    "# Needs to execute marxan from the marxan root folder in order to make the file find the required data.\n",
    "os.chdir(MARXAN_FOLDER)\n",
    "\n",
    "with subprocess.Popen([MARXAN_EXECUTABLE],\n",
    "                             stdout=subprocess.PIPE,\n",
    "                             stderr=subprocess.STDOUT,\n",
    "                             universal_newlines=True,\n",
    "                          bufsize=-1) as process:\n",
    "\n",
    "    while process.poll() is None:\n",
    "        output = process.stdout.readline()\n",
    "        if output:\n",
    "            print(output.strip())\n",
    "\n",
    "os.chdir('/home/jovyan/work/notebooks/Lab')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Postprocess Output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This are the validation data types that we need to produce before ingesting it in the DB.  \n",
    "Next step will connect to both DB and will extract the tables we require and generate pydantic models from them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine, MetaData\n",
    "from sqlalchemy.ext.automap import automap_base\n",
    "from sa2schema.to.pydantic import sa_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/IPython/core/display.py:904: UserWarning: JSON expects JSONable dict or list, not JSON strings\n",
      "  warnings.warn(\"JSON expects JSONable dict or list, not JSON strings\")\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "additionalProperties": false,
       "description": "Base for SqlAlchemy models.\n\nThis model will brutely load all unloaded attributes, even if that triggers hundreds of additional SQL queries.\n\nWhen encountering recursive relationships, it will replace their recursive values with `None`. Make sure your schema is ready for that.\nUse it with `make_optional`; that's the best thing.",
       "properties": {
        "created_at": {
         "format": "date-time",
         "title": "Created At",
         "type": "string"
        },
        "display_name": {
         "title": "Display Name",
         "type": "string"
        },
        "email": {
         "title": "Email",
         "type": "string"
        },
        "fname": {
         "title": "Fname",
         "type": "string"
        },
        "id": {
         "title": "Id"
        },
        "is_active": {
         "title": "Is Active",
         "type": "boolean"
        },
        "is_deleted": {
         "title": "Is Deleted",
         "type": "boolean"
        },
        "lname": {
         "title": "Lname",
         "type": "string"
        },
        "metadata": {
         "title": "Metadata",
         "type": "object"
        },
        "password_hash": {
         "title": "Password Hash",
         "type": "string"
        }
       },
       "required": [
        "id",
        "email",
        "created_at",
        "password_hash"
       ],
       "title": "users",
       "type": "object"
      },
      "text/plain": [
       "<IPython.core.display.JSON object>"
      ]
     },
     "execution_count": 63,
     "metadata": {
      "application/json": {
       "expanded": false,
       "root": "root"
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "JSON(sa_model(apiBase.classes.users).schema_json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['public.output_results', 'public.scenarios', 'public.users', 'public.projects', 'public.organizations'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sqlalchemy/dialects/postgresql/base.py:3198: SAWarning: Did not recognize type 'geometry' of column 'extent'\n",
      "  util.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/sqlalchemy/dialects/postgresql/base.py:3528: SAWarning: Skipped unsupported reflection of expression-based index unique_user_emails\n",
      "  util.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/sqlalchemy/dialects/postgresql/base.py:3528: SAWarning: Skipped unsupported reflection of expression-based index unique_organization_names\n",
      "  util.warn(\n",
      "/opt/conda/lib/python3.8/site-packages/IPython/core/display.py:904: UserWarning: JSON expects JSONable dict or list, not JSON strings\n",
      "  warnings.warn(\"JSON expects JSONable dict or list, not JSON strings\")\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "additionalProperties": false,
       "description": "Base for SqlAlchemy models.\n\nThis model will brutely load all unloaded attributes, even if that triggers hundreds of additional SQL queries.\n\nWhen encountering recursive relationships, it will replace their recursive values with `None`. Make sure your schema is ready for that.\nUse it with `make_optional`; that's the best thing.",
       "properties": {
        "connectivity": {
         "title": "Connectivity",
         "type": "number"
        },
        "connectivity_total": {
         "title": "Connectivity Total",
         "type": "number"
        },
        "cost": {
         "title": "Cost",
         "type": "number"
        },
        "id": {
         "title": "Id"
        },
        "metadata": {
         "title": "Metadata",
         "type": "object"
        },
        "missing_values": {
         "title": "Missing Values",
         "type": "number"
        },
        "mpm": {
         "title": "Mpm",
         "type": "number"
        },
        "penalty": {
         "title": "Penalty",
         "type": "number"
        },
        "planning_units": {
         "title": "Planning Units",
         "type": "number"
        },
        "run_id": {
         "title": "Run Id",
         "type": "integer"
        },
        "scenarios_id": {
         "title": "Scenarios Id"
        },
        "score": {
         "title": "Score",
         "type": "number"
        },
        "shortfall": {
         "title": "Shortfall",
         "type": "number"
        }
       },
       "required": [
        "id"
       ],
       "title": "output_results",
       "type": "object"
      },
      "text/plain": [
       "<IPython.core.display.JSON object>"
      ]
     },
     "execution_count": 54,
     "metadata": {
      "application/json": {
       "expanded": false,
       "root": "root"
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "api_engine = create_engine(f\"postgres://marxan-api:marxan-api@marxan-postgresql-api:5432/marxan-api\")\n",
    "api_meta = MetaData(schema=\"public\")\n",
    "api_meta.reflect(bind=api_engine, only=['output_results'])\n",
    "print(api_meta.tables.keys())\n",
    "apiBase = automap_base(metadata=api_meta)\n",
    "apiBase.prepare()\n",
    "#mapped classes are ready\n",
    "OutputResults = sa_model(apiBase.classes.output_results) #classes: output_results, scenarios, projects, organizations, users\n",
    "JSON(OutputResults.schema_json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/sqlalchemy/dialects/postgresql/base.py:3198: SAWarning: Did not recognize type 'geometry' of column 'the_geom'\n",
      "  util.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['public.spatial_ref_sys', 'public.migrations', 'public.admin_regions', 'public.admin_regions_0', 'public.admin_regions_1', 'public.admin_regions_2', 'public.wdpa', 'public.features_data', 'public.scenario_features_data', 'public.planning_units_geom', 'public.planning_units_geom_square', 'public.planning_units_geom_hexagon', 'public.planning_units_geom_irregular', 'public.scenarios_pu_data', 'public.scenarios_pu_cost_data', 'public.output_results_data'])\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "additionalProperties": false,
       "description": "Base for SqlAlchemy models.\n\nThis model will brutely load all unloaded attributes, even if that triggers hundreds of additional SQL queries.\n\nWhen encountering recursive relationships, it will replace their recursive values with `None`. Make sure your schema is ready for that.\nUse it with `make_optional`; that's the best thing.",
       "properties": {
        "id": {
         "title": "Id"
        },
        "missing_values": {
         "title": "Missing Values",
         "type": "object"
        },
        "puid": {
         "title": "Puid",
         "type": "integer"
        },
        "run_id": {
         "title": "Run Id"
        },
        "scenario_id": {
         "title": "Scenario Id"
        },
        "value": {
         "title": "Value",
         "type": "number"
        }
       },
       "required": [
        "id"
       ],
       "title": "output_results_data",
       "type": "object"
      },
      "text/plain": [
       "<IPython.core.display.JSON object>"
      ]
     },
     "execution_count": 64,
     "metadata": {
      "application/json": {
       "expanded": false,
       "root": "root"
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "geo_api_engine = create_engine(f\"postgres://marxan-geo-api:marxan-geo-api@marxan-postgresql-geo-api:5432/marxan-geo-api\")\n",
    "geo_api_meta = MetaData(schema=\"public\")\n",
    "geo_api_meta.reflect(bind=geo_api_engine)\n",
    "print(geo_api_meta.tables.keys())\n",
    "geoApiBase = automap_base(metadata=geo_api_meta)\n",
    "geoApiBase.prepare()\n",
    "#mapped classes are ready\n",
    "OutputResultsData = sa_model(geoApiBase.classes.output_results_data)\n",
    "JSON(OutputResultsData.schema_json())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the models for validation are ready we can use the same rules we had above to load / save from pandas. `CreateFileFromDF(filename: str, df: Type['Dataframe'], model: Type['Model'])`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CreateFileFromDF(filename: str, df: Type['Dataframe'], model=OutputResultsData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CreateFileFromDF(filename: str, df: Type['Dataframe'], model=OutputResults)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
